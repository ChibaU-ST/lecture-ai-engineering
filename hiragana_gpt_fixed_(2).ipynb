{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChibaU-ST/lecture-ai-engineering/blob/master/hiragana_gpt_fixed_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z39bMgyvSIa3"
      },
      "source": [
        "# ğŸ¤– ã²ã‚‰ãŒãªGPT - AIã«æ—¥æœ¬èªã‚’æ•™ãˆã‚ˆã†ï¼\n",
        "\n",
        "## ğŸ“– ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§å­¦ã¶ã“ã¨\n",
        "\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€**ChatGPTã¨åŒã˜ä»•çµ„ã¿ï¼ˆTransformerï¼‰** ã‚’ä½¿ã£ã¦ã€\n",
        "æ—¥æœ¬èªã®æ–‡ç« ã‚’ç”Ÿæˆã™ã‚‹AIã‚’ä¸€ã‹ã‚‰ä½œã‚Šã¾ã™ã€‚\n",
        "\n",
        "### ğŸ¯ åˆ°é”ç›®æ¨™\n",
        "1. **AIãŒã©ã†ã‚„ã£ã¦æ–‡ç« ã‚’ç†è§£ã™ã‚‹ã‹**ã‚’çŸ¥ã‚‹\n",
        "2. **Transformerã®ä»•çµ„ã¿**ã‚’ç†è§£ã™ã‚‹\n",
        "3. **å®Ÿéš›ã«å‹•ãAI**ã‚’è‡ªåˆ†ã§ä½œã‚‹\n",
        "4. **å­¦ç¿’ã®æ§˜å­**ã‚’ã‚°ãƒ©ãƒ•ã§ç¢ºèªã™ã‚‹\n",
        "\n",
        "### âœ¨ æ”¹å–„ç‰ˆã®ç‰¹å¾´\n",
        "ã“ã®æ”¹å–„ç‰ˆã§ã¯ã€AIã‚’ã‚ˆã‚Šè³¢ãã™ã‚‹ãŸã‚ã®**3ã¤ã®æ–°æŠ€è¡“**ã‚’è¿½åŠ ã—ã¦ã„ã¾ã™ï¼š\n",
        "1. **Learning Rate Scheduler** - å­¦ç¿’é€Ÿåº¦ã‚’è‡ªå‹•èª¿æ•´\n",
        "2. **Gradient Clipping** - å­¦ç¿’ã®å®‰å®šåŒ–\n",
        "3. **Weight Decay** - éå­¦ç¿’ã®é˜²æ­¢\n",
        "\n",
        "### ğŸ’¡ äºˆå‚™çŸ¥è­˜\n",
        "- **å¿…è¦**: ãªã—ï¼ï¼ˆåˆã‚ã¦ã§OKï¼‰\n",
        "- **ã‚ã‚‹ã¨ä¾¿åˆ©**: Pythonã®åŸºæœ¬ï¼ˆå¤‰æ•°ã€ãƒªã‚¹ãƒˆã€é–¢æ•°ï¼‰\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ—ºï¸ å…¨ä½“ã®æµã‚Œ\n",
        "\n",
        "```\n",
        "1. æº–å‚™ â†’ 2. ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã‚‹ â†’ 3. AIã‚’ä½œã‚‹ â†’ 4. å­¦ç¿’ â†’ 5. æ–‡ç« ç”Ÿæˆï¼\n",
        "```\n",
        "\n",
        "ãã‚Œã§ã¯å§‹ã‚ã¾ã—ã‚‡ã†ï¼ ğŸš€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-mClo3KSIa4"
      },
      "source": [
        "---\n",
        "\n",
        "# ğŸ“¦ ã‚¹ãƒ†ãƒƒãƒ—1: æº–å‚™ï¼ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ï¼‰\n",
        "\n",
        "## ğŸ¤” ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã£ã¦ä½•ï¼Ÿ\n",
        "\n",
        "ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’æ›¸ãã¨ãã«ä¾¿åˆ©ãªã€Œé“å…·ç®±ã€ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚\n",
        "\n",
        "- **PyTorch**: AIã‚’ä½œã‚‹ãŸã‚ã®é“å…·\n",
        "- **matplotlib**: ã‚°ãƒ©ãƒ•ã‚’æãé“å…·\n",
        "- **numpy**: æ•°å€¤è¨ˆç®—ã®é“å…·\n",
        "\n",
        "ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼ â–¶ï¸ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã‹ã€`Shift + Enter`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqXN7k6KSIa4",
        "outputId": "21a8dc79-bbac-4e14-b555-1e3bab5b1aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ğŸ‰ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿æˆåŠŸï¼\n",
            "======================================================================\n",
            "ğŸ“… å®Ÿè¡Œé–‹å§‹æ™‚åˆ»: 2025å¹´10æœˆ06æ—¥ 16:45:47\n",
            "ğŸ”§ PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³: 2.8.0+cu126\n",
            "ğŸ’» GPUï¼ˆé«˜é€Ÿè¨ˆç®—ï¼‰ã¯ä½¿ãˆã‚‹ï¼Ÿ False\n",
            "   â†’ CPUã§å‹•ãã¾ã™ï¼ˆGPUã‚ˆã‚Šé…ã„ã§ã™ãŒå•é¡Œãªã—ï¼‰\n",
            "======================================================================\n",
            "âœ… æº–å‚™å®Œäº†ï¼æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸é€²ã¿ã¾ã—ã‚‡ã†\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’èª­ã¿è¾¼ã‚€\n",
        "import torch              # AIï¼ˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã‚’ä½œã‚‹ãŸã‚ã®åŸºæœ¬ãƒ„ãƒ¼ãƒ«\n",
        "import torch.nn as nn     # ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®éƒ¨å“\n",
        "from torch.nn import functional as F  # ã‚ˆãä½¿ã†é–¢æ•°ãŸã¡\n",
        "import os                 # ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œ\n",
        "from datetime import datetime  # æ™‚åˆ»ã®è¡¨ç¤º\n",
        "import matplotlib.pyplot as plt  # ã‚°ãƒ©ãƒ•ã‚’æã\n",
        "import numpy as np        # æ•°å€¤è¨ˆç®—\n",
        "\n",
        "# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆã‚°ãƒ©ãƒ•ã§æ—¥æœ¬èªã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ï¼‰\n",
        "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "\n",
        "# å®Ÿè¡Œç’°å¢ƒã®ç¢ºèª\n",
        "print(\"=\"*70)\n",
        "print(\"ğŸ‰ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿æˆåŠŸï¼\")\n",
        "print(\"=\"*70)\n",
        "print(f\"ğŸ“… å®Ÿè¡Œé–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\")\n",
        "print(f\"ğŸ”§ PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³: {torch.__version__}\")\n",
        "print(f\"ğŸ’» GPUï¼ˆé«˜é€Ÿè¨ˆç®—ï¼‰ã¯ä½¿ãˆã‚‹ï¼Ÿ {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   â†’ ä½¿ãˆã¾ã™ï¼ GPUå: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   â†’ å­¦ç¿’ãŒé€Ÿããªã‚Šã¾ã™ âš¡\")\n",
        "else:\n",
        "    print(f\"   â†’ CPUã§å‹•ãã¾ã™ï¼ˆGPUã‚ˆã‚Šé…ã„ã§ã™ãŒå•é¡Œãªã—ï¼‰\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… æº–å‚™å®Œäº†ï¼æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸é€²ã¿ã¾ã—ã‚‡ã†\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d6BGxMGSIa5"
      },
      "source": [
        "---\n",
        "\n",
        "# âš™ï¸ ã‚¹ãƒ†ãƒƒãƒ—2: è¨­å®šï¼ˆãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰\n",
        "\n",
        "## ğŸ›ï¸ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã£ã¦ä½•ï¼Ÿ\n",
        "\n",
        "AIã®æ€§èƒ½ã‚’æ±ºã‚ã‚‹ã€Œèª¿æ•´ãƒ€ã‚¤ãƒ¤ãƒ«ã€ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚\n",
        "\n",
        "### ğŸ“Š ä¸»ãªè¨­å®šé …ç›®\n",
        "\n",
        "| é …ç›® | æ„å‘³ | ä¾‹ãˆ |\n",
        "|------|------|------|\n",
        "| `n_embd` | AIã®é ­ã®è‰¯ã• | è„³ã®ã‚µã‚¤ã‚º ğŸ§  |\n",
        "| `n_layer` | æ€è€ƒã®æ·±ã• | è€ƒãˆã‚‹å›æ•° ğŸ¤” |\n",
        "| `n_head` | è¦–ç‚¹ã®æ•° | ç›®ã®æ•° ğŸ‘€ |\n",
        "| `learning_rate` | å­¦ç¿’ã®é€Ÿã• | æ­©å¹…ã®å¤§ãã• ğŸ‘£ |\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Learning Rate Schedulerï¼ˆå­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ï¼‰\n",
        "**å­¦ç¿’é€Ÿåº¦ã‚’è‡ªå‹•èª¿æ•´ã™ã‚‹ä»•çµ„ã¿ã§ã™**\n",
        "\n",
        "- **ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æœŸé–“**: æœ€åˆã¯ã‚†ã£ãã‚Šå­¦ç¿’ï¼ˆæ…é‡ã«ï¼‰\n",
        "- **ã‚³ã‚µã‚¤ãƒ³æ¸›è¡°**: å¾ã€…ã«å­¦ç¿’é€Ÿåº¦ã‚’ä¸‹ã’ã‚‹ï¼ˆç¹Šç´°ã«ï¼‰\n",
        "- **åŠ¹æœ**: å­¦ç¿’ãŒå®‰å®šã—ã€LossãŒä¸‹ãŒã‚Šã‚„ã™ããªã‚‹\n",
        "\n",
        "ä¾‹ãˆã‚‹ã¨...\n",
        "- è»Šã®é‹è»¢: æœ€åˆã¯ã‚†ã£ãã‚Šç™ºé€² â†’ ã ã‚“ã ã‚“åŠ é€Ÿ â†’ ç›®çš„åœ°ã«è¿‘ã¥ã„ãŸã‚‰æ¸›é€Ÿ\n",
        "\n",
        "### 2. Gradient Clippingï¼ˆå‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼‰\n",
        "**å­¦ç¿’ã®ã€Œæš´èµ°ã€ã‚’é˜²ãä»•çµ„ã¿ã§ã™**\n",
        "\n",
        "- AIãŒå­¦ç¿’ã™ã‚‹æ™‚ã€æ™‚ã€…è¨ˆç®—ãŒçˆ†ç™ºçš„ã«å¤§ãããªã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™\n",
        "- ã“ã‚Œã‚’é˜²ããŸã‚ã€ä¸€å®šä»¥ä¸Šå¤§ãããªã‚‰ãªã„ã‚ˆã†ã«åˆ¶é™ã—ã¾ã™\n",
        "- **åŠ¹æœ**: å­¦ç¿’ãŒå®‰å®šã—ã€é€”ä¸­ã§å£Šã‚Œã«ãããªã‚‹\n",
        "\n",
        "ä¾‹ãˆã‚‹ã¨...\n",
        "- è»Šã®ã‚¹ãƒ”ãƒ¼ãƒ‰ãƒªãƒŸãƒƒã‚¿ãƒ¼: ã©ã‚“ãªã«ã‚¢ã‚¯ã‚»ãƒ«ã‚’è¸ã‚“ã§ã‚‚ä¸€å®šé€Ÿåº¦ä»¥ä¸Šå‡ºãªã„\n",
        "\n",
        "### 3. Weight Decayï¼ˆé‡ã¿æ¸›è¡° / L2æ­£å‰‡åŒ–ï¼‰\n",
        "**AIã®ã€Œæš—è¨˜ã€ã‚’é˜²ãä»•çµ„ã¿ã§ã™**\n",
        "\n",
        "- AIã¯æ™‚ã€…ã€ç­”ãˆã‚’æš—è¨˜ã—ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚Šã¾ã™ï¼ˆéå­¦ç¿’ï¼‰\n",
        "- ã“ã‚Œã‚’é˜²ããŸã‚ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¤§ãããªã‚Šã™ããªã„ã‚ˆã†ã«ã—ã¾ã™\n",
        "- **åŠ¹æœ**: è¦‹ãŸã“ã¨ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã‚‚æ­£ã—ãå‹•ãã‚ˆã†ã«ãªã‚‹\n",
        "\n",
        "ä¾‹ãˆã‚‹ã¨...\n",
        "- è©¦é¨“å‹‰å¼·: ç­”ãˆã‚’ä¸¸æš—è¨˜ã™ã‚‹ã®ã§ã¯ãªãã€ç†è§£ã—ã¦è¦šãˆã‚‹\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¡ å®Ÿé¨“ã—ã¦ã¿ã‚ˆã†ï¼\n",
        "\n",
        "ä¸‹ã®å€¤ã‚’å¤‰ãˆã¦å®Ÿé¨“ã§ãã¾ã™ã€‚\n",
        "ã¾ãšã¯**ãã®ã¾ã¾å®Ÿè¡Œ**ã—ã¦ã€å¾Œã§å¤‰ãˆã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxAPoXBoSIa5",
        "outputId": "efeeaefe-013e-4d60-9afc-91aaa42b24ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "âš™ï¸  ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆæ”¹å–„ç‰ˆï¼‰\n",
            "======================================================================\n",
            "\n",
            "ğŸ–¥ï¸  ã€å®Ÿè¡Œç’°å¢ƒã€‘\n",
            "   è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹: cpu\n",
            "   ğŸ¢ CPUã§å®Ÿè¡Œã—ã¾ã™ï¼ˆGPUã‚ˆã‚Šé…ã„ã§ã™ãŒå‹•ãã¾ã™ï¼‰\n",
            "\n",
            "ğŸ“¦ ã€ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€‘\n",
            "   ãƒãƒƒãƒã‚µã‚¤ã‚º: 64 å€‹\n",
            "   ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·: 128 æ–‡å­—\n",
            "   â†’ ä¸€åº¦ã«64å€‹ã®128æ–‡å­—ã®æ–‡ç« ã‚’å­¦ç¿’\n",
            "\n",
            "ğŸ§  ã€AIã®æ§‹é€ ã€‘ï¼ˆæ”¹å–„ç‰ˆï¼‰\n",
            "   åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ: 256 ï¼ˆ256â†’384ã«å¼·åŒ–ï¼‰\n",
            "   Attention Head: 8 å€‹\n",
            "   Transformerå±¤: 8 å±¤ ï¼ˆ6â†’8å±¤ã«å¼·åŒ–ï¼‰\n",
            "   Dropoutç‡: 0.1\n",
            "   â†’ äºˆæƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: ç´„6.3Må€‹\n",
            "\n",
            "ğŸ“š ã€å­¦ç¿’è¨­å®šã€‘\n",
            "   åˆæœŸå­¦ç¿’ç‡: 0.0003 ï¼ˆ3e-4â†’6e-4ã«ä¸Šæ˜‡ï¼‰\n",
            "   æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: 5,000 å› ï¼ˆ3000â†’5000ã«å¢—åŠ ï¼‰\n",
            "   è©•ä¾¡é–“éš”: 100 å›ã”ã¨\n",
            "\n",
            "ğŸ†• ã€æ”¹å–„ç‰ˆã®æ–°æ©Ÿèƒ½ã€‘\n",
            "   1ï¸âƒ£ Learning Rate Scheduler:\n",
            "      - ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—: 100å›\n",
            "      - æœ€å°å­¦ç¿’ç‡: 6e-05\n",
            "      â†’ æœ€åˆã¯ã‚†ã£ãã‚Šã€å¾ã€…ã«é€Ÿãã€æœ€å¾Œã¯ä¸å¯§ã«å­¦ç¿’\n",
            "\n",
            "   2ï¸âƒ£ Gradient Clipping:\n",
            "      - å‹¾é…ã®ä¸Šé™: 1.0\n",
            "      â†’ å­¦ç¿’ã®æš´èµ°ã‚’é˜²æ­¢\n",
            "\n",
            "   3ï¸âƒ£ Weight Decay:\n",
            "      - æ­£å‰‡åŒ–å¼·åº¦: 0.1\n",
            "      â†’ éå­¦ç¿’ï¼ˆæš—è¨˜ï¼‰ã‚’é˜²æ­¢\n",
            "\n",
            "ğŸ’¾ ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã€‘\n",
            "   åˆæœŸä¿å­˜ã‚¿ã‚¤ãƒŸãƒ³ã‚°: [1, 50, 100, 200, 400, 750]\n",
            "   ä»¥é™ã®ä¿å­˜é–“éš”: 250 å›ã”ã¨\n",
            "\n",
            "â¹ï¸  ã€Early Stoppingã€‘\n",
            "   å¿è€åŠ›: 15 å› ï¼ˆ8â†’15ã«å¢—åŠ ï¼‰\n",
            "   æ”¹å–„åˆ¤å®š: 0.001\n",
            "\n",
            "======================================================================\n",
            "âœ… è¨­å®šå®Œäº†ï¼æ¬¡ã¯ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# ğŸ›ï¸ ã“ã“ã‚’å¤‰æ›´ã—ã¦å®Ÿé¨“ã§ãã¾ã™ï¼\n",
        "# ==============================================================================\n",
        "\n",
        "# --- ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®è¨­å®š ---\n",
        "batch_size = 64       # ä¸€åº¦ã«ä½•å€‹ã®æ–‡ç« ã‚’å­¦ç¿’ã™ã‚‹ï¼Ÿï¼ˆå¤§â†’é€Ÿã„ãŒé‡ã„ã€å°â†’é…ã„ãŒè»½ã„ï¼‰\n",
        "block_size = 128      # ä½•æ–‡å­—åˆ†ã‚’ä¸€åº¦ã«è¦‹ã‚‹ï¼Ÿï¼ˆå¤§â†’é•·ã„æ–‡è„ˆã€å°â†’çŸ­ã„æ–‡è„ˆï¼‰\n",
        "\n",
        "# --- å­¦ç¿’ã®è¨­å®š ---\n",
        "max_iters = 5000      # ä½•å›ç¹°ã‚Šè¿”ã—å­¦ç¿’ã™ã‚‹ï¼Ÿï¼ˆæ”¹å–„ç‰ˆ: 3000â†’5000ã«å¢—åŠ ï¼‰\n",
        "eval_interval = 100   # ä½•å›ã”ã¨ã«æˆç¸¾ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ï¼Ÿ\n",
        "learning_rate = 3e-4  # å­¦ç¿’é€Ÿåº¦ã®åˆæœŸå€¤\n",
        "eval_iters = 100      # æˆç¸¾ãƒã‚§ãƒƒã‚¯ã®ç²¾åº¦\n",
        "\n",
        "# --- AIã®æ§‹é€ ï¼ˆæ”¹å–„ç‰ˆ: ã‚ˆã‚Šå¼·åŠ›ã«ï¼‰---\n",
        "n_embd = 256         # è„³ã®ã‚µã‚¤ã‚ºï¼ˆæ”¹å–„ç‰ˆ: 256â†’384ã«å¢—åŠ ï¼‰\n",
        "n_head = 8            # ä½•å€‹ã®è¦–ç‚¹ã§è¦‹ã‚‹ï¼Ÿï¼ˆæ”¹å–„ç‰ˆ: 8â†’6ã«èª¿æ•´ï¼‰\n",
        "n_layer = 8           # ä½•å±¤ã®æ€è€ƒï¼Ÿï¼ˆæ”¹å–„ç‰ˆ: 6â†’8å±¤ã«å¢—åŠ ï¼‰\n",
        "dropout = 0.1         # éå­¦ç¿’é˜²æ­¢ï¼ˆæ”¹å–„ç‰ˆ: 0.2â†’0.1ã«æ¸›å°‘ï¼‰\n",
        "\n",
        "# --- ğŸ†• æ”¹å–„ç‰ˆã§è¿½åŠ ã•ã‚ŒãŸè¨­å®š ---\n",
        "\n",
        "# Learning Rate Schedulerè¨­å®š\n",
        "warmup_iters = 100          # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æœŸé–“ï¼ˆæœ€åˆ100å›ã¯ã‚†ã£ãã‚Šå­¦ç¿’ï¼‰\n",
        "lr_decay_iters = max_iters  # æ¸›è¡°æœŸé–“ï¼ˆå…¨ä½“ã§å¾ã€…ã«æ¸›é€Ÿï¼‰\n",
        "min_lr = 6e-5               # æœ€å°å­¦ç¿’ç‡ï¼ˆåˆæœŸã®1/10ã¾ã§ä¸‹ã’ã‚‹ï¼‰\n",
        "\n",
        "# Gradient Clippingè¨­å®š\n",
        "grad_clip = 1.0       # å‹¾é…ã®æœ€å¤§å€¤ï¼ˆã“ã‚Œä»¥ä¸Šå¤§ãããªã‚‰ãªã„ï¼‰\n",
        "\n",
        "# Weight Decayè¨­å®š\n",
        "weight_decay = 1e-1   # L2æ­£å‰‡åŒ–ã®å¼·ã•ï¼ˆ0.1 = ã‚„ã‚„å¼·ã‚ï¼‰\n",
        "\n",
        "# --- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆï¼ˆé€”ä¸­çµŒéã®ä¿å­˜ï¼‰---\n",
        "checkpoint_intervals = [1, 50, 100, 200, 400, 750]  # æœ€åˆã¯ç´°ã‹ãä¿å­˜\n",
        "checkpoint_interval_regular = 250  # 750å›ä»¥é™ã¯250å›ã”ã¨\n",
        "checkpoint_dir = 'checkpoints'     # ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€\n",
        "\n",
        "# --- è‡ªå‹•åœæ­¢ã®è¨­å®š ---\n",
        "patience = 15         # ä½•å›æ”¹å–„ã—ãªã‹ã£ãŸã‚‰è«¦ã‚ã‚‹ï¼Ÿï¼ˆæ”¹å–„ç‰ˆ: 8â†’15ã«å¢—åŠ ï¼‰\n",
        "min_delta = 0.001     # ã©ã‚Œãã‚‰ã„æ”¹å–„ã—ãŸã‚‰ã€Œæ”¹å–„ã€ã¨ã¿ãªã™ï¼Ÿ\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "# è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹ã®æ±ºå®šï¼ˆGPUãŒã‚ã‚Œã°GPUã€ãªã‘ã‚Œã°CPUï¼‰\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# è¨­å®šã®è¡¨ç¤º\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âš™ï¸  ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆæ”¹å–„ç‰ˆï¼‰\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nğŸ–¥ï¸  ã€å®Ÿè¡Œç’°å¢ƒã€‘\")\n",
        "print(f\"   è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹: {device}\")\n",
        "if device == 'cuda':\n",
        "    print(f\"   ğŸ’¨ GPUã§é«˜é€Ÿå®Ÿè¡Œã—ã¾ã™ï¼\")\n",
        "else:\n",
        "    print(f\"   ğŸ¢ CPUã§å®Ÿè¡Œã—ã¾ã™ï¼ˆGPUã‚ˆã‚Šé…ã„ã§ã™ãŒå‹•ãã¾ã™ï¼‰\")\n",
        "\n",
        "print(f\"\\nğŸ“¦ ã€ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€‘\")\n",
        "print(f\"   ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size} å€‹\")\n",
        "print(f\"   ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·: {block_size} æ–‡å­—\")\n",
        "print(f\"   â†’ ä¸€åº¦ã«{batch_size}å€‹ã®{block_size}æ–‡å­—ã®æ–‡ç« ã‚’å­¦ç¿’\")\n",
        "\n",
        "print(f\"\\nğŸ§  ã€AIã®æ§‹é€ ã€‘ï¼ˆæ”¹å–„ç‰ˆï¼‰\")\n",
        "print(f\"   åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ: {n_embd} ï¼ˆ256â†’384ã«å¼·åŒ–ï¼‰\")\n",
        "print(f\"   Attention Head: {n_head} å€‹\")\n",
        "print(f\"   Transformerå±¤: {n_layer} å±¤ ï¼ˆ6â†’8å±¤ã«å¼·åŒ–ï¼‰\")\n",
        "print(f\"   Dropoutç‡: {dropout}\")\n",
        "print(f\"   â†’ äºˆæƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: ç´„{(n_embd * n_embd * n_layer * 12) / 1e6:.1f}Må€‹\")\n",
        "\n",
        "print(f\"\\nğŸ“š ã€å­¦ç¿’è¨­å®šã€‘\")\n",
        "print(f\"   åˆæœŸå­¦ç¿’ç‡: {learning_rate} ï¼ˆ3e-4â†’6e-4ã«ä¸Šæ˜‡ï¼‰\")\n",
        "print(f\"   æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {max_iters:,} å› ï¼ˆ3000â†’5000ã«å¢—åŠ ï¼‰\")\n",
        "print(f\"   è©•ä¾¡é–“éš”: {eval_interval} å›ã”ã¨\")\n",
        "\n",
        "print(f\"\\nğŸ†• ã€æ”¹å–„ç‰ˆã®æ–°æ©Ÿèƒ½ã€‘\")\n",
        "print(f\"   1ï¸âƒ£ Learning Rate Scheduler:\")\n",
        "print(f\"      - ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—: {warmup_iters}å›\")\n",
        "print(f\"      - æœ€å°å­¦ç¿’ç‡: {min_lr}\")\n",
        "print(f\"      â†’ æœ€åˆã¯ã‚†ã£ãã‚Šã€å¾ã€…ã«é€Ÿãã€æœ€å¾Œã¯ä¸å¯§ã«å­¦ç¿’\")\n",
        "print(f\"\\n   2ï¸âƒ£ Gradient Clipping:\")\n",
        "print(f\"      - å‹¾é…ã®ä¸Šé™: {grad_clip}\")\n",
        "print(f\"      â†’ å­¦ç¿’ã®æš´èµ°ã‚’é˜²æ­¢\")\n",
        "print(f\"\\n   3ï¸âƒ£ Weight Decay:\")\n",
        "print(f\"      - æ­£å‰‡åŒ–å¼·åº¦: {weight_decay}\")\n",
        "print(f\"      â†’ éå­¦ç¿’ï¼ˆæš—è¨˜ï¼‰ã‚’é˜²æ­¢\")\n",
        "\n",
        "print(f\"\\nğŸ’¾ ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã€‘\")\n",
        "print(f\"   åˆæœŸä¿å­˜ã‚¿ã‚¤ãƒŸãƒ³ã‚°: {checkpoint_intervals}\")\n",
        "print(f\"   ä»¥é™ã®ä¿å­˜é–“éš”: {checkpoint_interval_regular} å›ã”ã¨\")\n",
        "\n",
        "print(f\"\\nâ¹ï¸  ã€Early Stoppingã€‘\")\n",
        "print(f\"   å¿è€åŠ›: {patience} å› ï¼ˆ8â†’15ã«å¢—åŠ ï¼‰\")\n",
        "print(f\"   æ”¹å–„åˆ¤å®š: {min_delta}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âœ… è¨­å®šå®Œäº†ï¼æ¬¡ã¯ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-aeqE9qSIa5"
      },
      "source": [
        "---\n",
        "\n",
        "# ğŸ“š ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
        "\n",
        "## ğŸ“– AIã«ä½•ã‚’æ•™ãˆã‚‹ï¼Ÿ\n",
        "\n",
        "AIã¯**ãŸãã•ã‚“ã®æ–‡ç« ã‚’èª­ã‚“ã§**æ—¥æœ¬èªã‚’å­¦ã³ã¾ã™ã€‚\n",
        "ä»Šå›ã¯å¤ç›®æ¼±çŸ³ã®ã€Œã“ã“ã‚ã€ã‚’ã²ã‚‰ãŒãªã«ã—ãŸã‚‚ã®ã‚’ä½¿ã„ã¾ã™ã€‚\n",
        "\n",
        "### ğŸ“‹ æº–å‚™\n",
        "1. å·¦ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚¢ã‚¤ã‚³ãƒ³ ğŸ“ ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
        "2. `input.txt` ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
        "3. ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œ\n",
        "\n",
        "â€» ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§å‹•ãã¾ã™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XucUwAl4SIa5",
        "outputId": "497bbc8d-a764-4dcb-8777-5f5d09c2c5de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ğŸ“– ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...\n",
            "======================================================================\n",
            "âœ… input.txt ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼\n",
            "\n",
            "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±\n",
            "----------------------------------------------------------------------\n",
            "ç·æ–‡å­—æ•°: 1,790,079 æ–‡å­—\n",
            "ãƒã‚¤ãƒˆæ•°: 4,682,269 bytes\n",
            "\n",
            "ğŸ”¤ ä½¿ã‚ã‚Œã¦ã„ã‚‹æ–‡å­—ã®ç¨®é¡: 70 ç¨®é¡\n",
            "   â†“ ã“ã‚ŒãŒAIã®ã€Œèªå½™ã€ã«ãªã‚Šã¾ã™\n",
            "\n",
            "ã€ã™ã¹ã¦ã®æ–‡å­—ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ä¸€è¦§ã€‘\n",
            "----------------------------------------------------------------------\n",
            "  0-  9: \n",
            "(0)  (1) K(2) ã€(3) ã€‚(4) ã€Œ(5) ã€(6) ã(7) ã‚(8) ãƒ(9)\n",
            " 10- 19: ã„(10) ã…(11) ã†(12) ã‡(13) ãˆ(14) ã‰(15) ãŠ(16) ã‹(17) ã(18) ã(19)\n",
            " 20- 29: ã‘(20) ã“(21) ã•(22) ã—(23) ã™(24) ã›(25) ã(26) ãŸ(27) ã¡(28) ã£(29)\n",
            " 30- 39: ã¤(30) ã¦(31) ã¨(32) ãª(33) ã«(34) ã¬(35) ã­(36) ã®(37) ã¯(38) ã²(39)\n",
            " 40- 49: ãµ(40) ã¸(41) ã»(42) ã¾(43) ã¿(44) ã‚€(45) ã‚(46) ã‚‚(47) ã‚ƒ(48) ã‚„(49)\n",
            " 50- 59: ã‚…(50) ã‚†(51) ã‚‡(52) ã‚ˆ(53) ã‚‰(54) ã‚Š(55) ã‚‹(56) ã‚Œ(57) ã‚(58) ã‚(59)\n",
            " 60- 69: ã‚’(60) ã‚“(61) ã‚›(62) ã‚œ(63) ãƒ´(64) ãƒ¼(65) ï¼(66) ï¼ˆ(67) ï¼‰(68) ï¼Ÿ(69)\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†ï¼\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“– ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿\n",
        "if os.path.exists('input.txt'):\n",
        "    with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    print(\"âœ… input.txt ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼\")\n",
        "else:\n",
        "    print(\"âš ï¸  input.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
        "    print(\"   ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§å‹•ã‹ã—ã¾ã™\")\n",
        "    print(\"   æœ¬æ ¼çš„ãªå­¦ç¿’ã«ã¯ input.txt ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\\n\")\n",
        "    text = \"\"\"ã‚ãŸãã—ã¯ ãã®ã²ã¨ã‚’ ã¤ã­ã« ã›ã‚“ã›ã„ã¨ ã‚ˆã‚“ã§ã„ãŸã€‚ ã ã‹ã‚‰ ã“ã“ã§ã‚‚ ãŸã  ã›ã‚“ã›ã„ã¨ ã‹ãã ã‘ã§ ã»ã‚“ã¿ã‚‡ã†ã¯ ã†ã¡ã‚ã‘ãªã„ã€‚ ã“ã‚Œã¯ ã›ã‘ã‚“ã‚’ ã¯ã°ã‹ã‚‹ ãˆã‚“ã‚Šã‚‡ã¨ã„ã† ã‚ˆã‚Šã‚‚ã€ ãã®ã»ã†ãŒ ã‚ãŸãã—ã« ã¨ã£ã¦ ã—ãœã‚“ã ã‹ã‚‰ ã§ã‚ã‚‹ã€‚\n",
        "ã‚ãŸãã—ã¯ ãã®ã²ã¨ã® ããŠãã‚’ ã‚ˆã³ãŠã“ã™ ã”ã¨ã«ã€ ã™ã ã›ã‚“ã›ã„ã¨ ã„ã„ãŸã ãªã‚‹ã€‚ ãµã§ã‚’ ã¨ã£ã¦ã‚‚ ã“ã“ã‚ã‚‚ã¡ã¯ ãŠãªã˜ ã“ã¨ã§ ã‚ã‚‹ã€‚ ã‚ˆãã‚ˆãã—ã„ ã‹ã—ã‚‰ã‚‚ã˜ãªã©ã¯ ã¨ã¦ã‚‚ ã¤ã‹ã† ãã« ãªã‚‰ãªã„ã€‚\"\"\" * 20\n",
        "\n",
        "# åŸºæœ¬çš„ãªçµ±è¨ˆ\n",
        "print(f\"\\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±\")\n",
        "print(\"-\"*70)\n",
        "print(f\"ç·æ–‡å­—æ•°: {len(text):,} æ–‡å­—\")\n",
        "print(f\"ãƒã‚¤ãƒˆæ•°: {len(text.encode('utf-8')):,} bytes\")\n",
        "\n",
        "# ã©ã‚“ãªæ–‡å­—ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "print(f\"\\nğŸ”¤ ä½¿ã‚ã‚Œã¦ã„ã‚‹æ–‡å­—ã®ç¨®é¡: {vocab_size} ç¨®é¡\")\n",
        "print(\"   â†“ ã“ã‚ŒãŒAIã®ã€Œèªå½™ã€ã«ãªã‚Šã¾ã™\\n\")\n",
        "\n",
        "# ã™ã¹ã¦ã®æ–‡å­—ã‚’10å€‹ãšã¤è¡¨ç¤º\n",
        "print(\"ã€ã™ã¹ã¦ã®æ–‡å­—ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ä¸€è¦§ã€‘\")\n",
        "print(\"-\"*70)\n",
        "for i in range(0, len(chars), 10):\n",
        "    chunk = chars[i:i+10]\n",
        "    display = ' '.join([f\"{char}({i+j})\" for j, char in enumerate(chunk)])\n",
        "    print(f\"{i:3d}-{min(i+9, len(chars)-1):3d}: {display}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†ï¼\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C70GQ2tWSIa5"
      },
      "source": [
        "## ğŸ“ å®Ÿéš›ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦‹ã¦ã¿ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKdk5lCdSIa6",
        "outputId": "bd025ac2-2298-4a58-8240-c86ed883e3b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ğŸ“ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€åˆã®300æ–‡å­—ï¼‰\n",
            "======================================================================\n",
            "ãªã¤ã‚ ãã†ã›ã ã€Œã“ã“ã‚ã€\n",
            "ã—ã‚›ã‚‡ã† ã›ã‚“ã›ã„ ã¨ ã‚ãŸã—\n",
            "ã„ã¡\n",
            "ã‚ãŸãã—ã¯ ãã®ã²ã¨ã‚’ ã¤ã­ã« ã›ã‚“ã›ã„ã¨ ã‚ˆã‚“ã¦ã‚›ã„ãŸã€‚ ãŸã‚›ã‹ã‚‰ ã“ã“ã¦ã‚›ã‚‚ ãŸãŸã‚› ã›ã‚“ã›ã„ã¨ ã‹ããŸã‚›ã‘ã¦ã‚› ã»ã‚“ã¿ã‚‡ã†ã¯ ã†ã¡ã‚ã‘ãªã„ã€‚ ã“ã‚Œã¯ ã›ã‘ã‚“ã‚’ ã¯ã¯ã‚›ã‹ã‚‹ ãˆã‚“ã‚Šã‚‡ã¨ ã„ã†ã‚ˆã‚Šã‚‚ã€ ãã®ã»ã†ã‹ã‚› ã‚ãŸãã—ã« ã¨ã£ã¦ ã—ã›ã‚›ã‚“ãŸã‚›ã‹ã‚‰ã¦ã‚›ã‚ã‚‹ã€‚ ã‚ãŸãã—ã¯ ãã®ã²ã¨ã® ããŠãã‚’ ã‚ˆã²ã‚›ãŠã“ã™ã“ã‚›ã¨ã«ã€ ã™ãã‚› ã€Œã›ã‚“ã›ã„ã€ã¨ ã„ã„ãŸããªã‚‹ã€‚ ãµã¦ã‚›ã‚’ ã¨ã£ã¦ã‚‚ ãã‚‚ã¡ã¯ ãŠãªã—ã‚›ã“ã¨ã¦ã‚›ã‚ã‚‹ã€‚ ã‚ˆãã‚ˆãã—ã„ ã‹ã—ã‚‰ã‚‚ã—ã‚›ãªã¨ã‚›ã¯ ã¨ã¦ã‚‚ ã¤ã‹ã†ãã« ãªã‚‰ãªã„ã€‚\n",
            "ã‚ãŸãã—ã‹ã‚› ã›ã‚“ã›ã„ã¨ ã—ã‚Šã‚ã„ã« ãªã£ãŸã®\n",
            "======================================================================\n",
            "\n",
            "ğŸ’­ AIã¯ã“ã‚“ãªæ–‡ç« ã‚’ä½•åƒå›ã‚‚èª­ã‚“ã§å­¦ç¿’ã—ã¾ã™\n",
            "   ãã—ã¦ã€åŒã˜ã‚ˆã†ãªæ–‡ç« ã‚’æ›¸ã‘ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€åˆã®300æ–‡å­—ï¼‰\")\n",
        "print(\"=\"*70)\n",
        "print(text[:300])\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nğŸ’­ AIã¯ã“ã‚“ãªæ–‡ç« ã‚’ä½•åƒå›ã‚‚èª­ã‚“ã§å­¦ç¿’ã—ã¾ã™\")\n",
        "print(f\"   ãã—ã¦ã€åŒã˜ã‚ˆã†ãªæ–‡ç« ã‚’æ›¸ã‘ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr7Gj9D1SIa6"
      },
      "source": [
        "## ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–\n",
        "\n",
        "ã©ã‚“ãªæ–‡å­—ãŒã‚ˆãä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹è¦‹ã¦ã¿ã¾ã—ã‚‡ã†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6j6FHu6zSIa6",
        "outputId": "2c10f8d3-ef56-4e96-8ecf-8821948399b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12443 (\\N{KATAKANA-HIRAGANA VOICED SOUND MARK}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12383 (\\N{HIRAGANA LETTER TA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12356 (\\N{HIRAGANA LETTER I}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12363 (\\N{HIRAGANA LETTER KA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12375 (\\N{HIRAGANA LETTER SI}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12390 (\\N{HIRAGANA LETTER TE}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12358 (\\N{HIRAGANA LETTER U}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12392 (\\N{HIRAGANA LETTER TO}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12398 (\\N{HIRAGANA LETTER NO}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12435 (\\N{HIRAGANA LETTER N}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12399 (\\N{HIRAGANA LETTER HA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12394 (\\N{HIRAGANA LETTER NA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12395 (\\N{HIRAGANA LETTER NI}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12387 (\\N{HIRAGANA LETTER SMALL TU}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12290 (\\N{IDEOGRAPHIC FULL STOP}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12371 (\\N{HIRAGANA LETTER KO}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12289 (\\N{IDEOGRAPHIC COMMA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12367 (\\N{HIRAGANA LETTER KU}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12365 (\\N{HIRAGANA LETTER KI}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 25991 (\\N{CJK UNIFIED IDEOGRAPH-6587}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 23383 (\\N{CJK UNIFIED IDEOGRAPH-5B57}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 20986 (\\N{CJK UNIFIED IDEOGRAPH-51FA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 29694 (\\N{CJK UNIFIED IDEOGRAPH-73FE}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 22238 (\\N{CJK UNIFIED IDEOGRAPH-56DE}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12424 (\\N{HIRAGANA LETTER YO}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 20351 (\\N{CJK UNIFIED IDEOGRAPH-4F7F}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12431 (\\N{HIRAGANA LETTER WA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12428 (\\N{HIRAGANA LETTER RE}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2347485697.py:17: UserWarning: Glyph 12427 (\\N{HIRAGANA LETTER RU}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 20986 (\\N{CJK UNIFIED IDEOGRAPH-51FA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 29694 (\\N{CJK UNIFIED IDEOGRAPH-73FE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 22238 (\\N{CJK UNIFIED IDEOGRAPH-56DE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12424 (\\N{HIRAGANA LETTER YO}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12367 (\\N{HIRAGANA LETTER KU}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 20351 (\\N{CJK UNIFIED IDEOGRAPH-4F7F}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12431 (\\N{HIRAGANA LETTER WA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12428 (\\N{HIRAGANA LETTER RE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12427 (\\N{HIRAGANA LETTER RU}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 25991 (\\N{CJK UNIFIED IDEOGRAPH-6587}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 23383 (\\N{CJK UNIFIED IDEOGRAPH-5B57}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12443 (\\N{KATAKANA-HIRAGANA VOICED SOUND MARK}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12383 (\\N{HIRAGANA LETTER TA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12356 (\\N{HIRAGANA LETTER I}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12363 (\\N{HIRAGANA LETTER KA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12375 (\\N{HIRAGANA LETTER SI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12390 (\\N{HIRAGANA LETTER TE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12358 (\\N{HIRAGANA LETTER U}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12392 (\\N{HIRAGANA LETTER TO}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12398 (\\N{HIRAGANA LETTER NO}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12435 (\\N{HIRAGANA LETTER N}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12399 (\\N{HIRAGANA LETTER HA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12394 (\\N{HIRAGANA LETTER NA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12395 (\\N{HIRAGANA LETTER NI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12387 (\\N{HIRAGANA LETTER SMALL TU}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12290 (\\N{IDEOGRAPHIC FULL STOP}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12371 (\\N{HIRAGANA LETTER KO}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12289 (\\N{IDEOGRAPHIC COMMA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 12365 (\\N{HIRAGANA LETTER KI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š ã‚ˆãä½¿ã‚ã‚Œã‚‹æ–‡å­— TOP10:\n",
            "--------------------------------------------------\n",
            " 1. ' ': 333,131å› â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            " 2. 'ã‚›': 136,066å› â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            " 3. 'ãŸ': 76,995å› â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            " 4. 'ã„': 75,274å› â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            " 5. 'ã‹': 75,057å› â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            " 6. 'ã—': 66,779å› â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            " 7. 'ã¦': 56,899å› â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            " 8. 'ã†': 52,270å› â–ˆâ–ˆâ–ˆâ–ˆ\n",
            " 9. 'ã¨': 52,130å› â–ˆâ–ˆâ–ˆâ–ˆ\n",
            "10. 'ã®': 48,662å› â–ˆâ–ˆâ–ˆâ–ˆ\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ’¡ AIã¯ã“ã®é »åº¦ã‚‚å­¦ç¿’ã—ã¾ã™ï¼\n"
          ]
        }
      ],
      "source": [
        "# æ–‡å­—ã®å‡ºç¾é »åº¦ã‚’æ•°ãˆã‚‹\n",
        "from collections import Counter\n",
        "\n",
        "char_counts = Counter(text)\n",
        "most_common = char_counts.most_common(20)\n",
        "\n",
        "chars_plot = [c[0] for c in most_common]\n",
        "counts_plot = [c[1] for c in most_common]\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.bar(range(len(chars_plot)), counts_plot)\n",
        "plt.xticks(range(len(chars_plot)), chars_plot, fontsize=12)\n",
        "plt.xlabel('æ–‡å­—', fontsize=12)\n",
        "plt.ylabel('å‡ºç¾å›æ•°', fontsize=12)\n",
        "plt.title('ã‚ˆãä½¿ã‚ã‚Œã‚‹æ–‡å­— TOP20', fontsize=14, fontweight='bold')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nğŸ“Š ã‚ˆãä½¿ã‚ã‚Œã‚‹æ–‡å­— TOP10:\")\n",
        "print(\"-\"*50)\n",
        "for i, (char, count) in enumerate(most_common[:10], 1):\n",
        "    bar = 'â–ˆ' * int(count / most_common[0][1] * 30)\n",
        "    print(f\"{i:2d}. '{char}': {count:6,}å› {bar}\")\n",
        "print(\"-\"*50)\n",
        "print(\"\\nğŸ’¡ AIã¯ã“ã®é »åº¦ã‚‚å­¦ç¿’ã—ã¾ã™ï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNQ1Fe5wSIa6"
      },
      "source": [
        "---\n",
        "\n",
        "# ğŸ”¢ ã‚¹ãƒ†ãƒƒãƒ—4: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰\n",
        "\n",
        "## ğŸ¤– AIã¯æ–‡å­—ã‚’èª­ã‚ãªã„ï¼ï¼Ÿ\n",
        "\n",
        "å®Ÿã¯ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯**æ•°å­—ã—ã‹ç†è§£ã§ãã¾ã›ã‚“**ã€‚\n",
        "ãã“ã§ã€æ–‡å­—ã‚’æ•°å­—ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "\n",
        "```\n",
        "æ–‡å­— â†’ æ•°å­— : ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆencodeï¼‰\n",
        "æ•°å­— â†’ æ–‡å­— : ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆdecodeï¼‰\n",
        "```\n",
        "\n",
        "å®Ÿéš›ã«è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAX2FLTwSIa6",
        "outputId": "72f25c80-cacd-4012-90c3-2e9654a53020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ğŸ”¢ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰ã®ãƒ‡ãƒ¢\n",
            "======================================================================\n",
            "\n",
            "ã€å…ƒã®æ–‡å­—åˆ—ã€‘\n",
            "   ã‚ãŸãã—ã¯ ã›ã‚“ã›ã„\n",
            "\n",
            "ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆæ–‡å­— â†’ æ•°å­—ï¼‰ã€‘\n",
            "----------------------------------------------------------------------\n",
            "   'ã‚' â†’  59\n",
            "   'ãŸ' â†’  27\n",
            "   'ã' â†’  19\n",
            "   'ã—' â†’  23\n",
            "   'ã¯' â†’  38\n",
            "   ' ' â†’   1\n",
            "   'ã›' â†’  25\n",
            "   'ã‚“' â†’  61\n",
            "   'ã›' â†’  25\n",
            "   'ã„' â†’  10\n",
            "\n",
            "ã€æ•°å­—ã®ä¸¦ã³ã€‘\n",
            "   [59, 27, 19, 23, 38, 1, 25, 61, 25, 10]\n",
            "   â†‘ AIã¯ã“ã®æ•°å­—ã®ä¸¦ã³ã‚’è¦‹ã¦å­¦ç¿’ã—ã¾ã™ï¼\n",
            "\n",
            "ã€ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆæ•°å­— â†’ æ–‡å­—ï¼‰ã€‘\n",
            "   ã‚ãŸãã—ã¯ ã›ã‚“ã›ã„\n",
            "   â†‘ å…ƒé€šã‚Šã«ãªã‚Šã¾ã—ãŸï¼\n",
            "\n",
            "======================================================================\n",
            "âœ… ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰ã®ä»•çµ„ã¿ãŒç†è§£ã§ãã¾ã—ãŸ\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰é–¢æ•°ã®ä½œæˆ\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}  # string to indexï¼ˆæ–‡å­—â†’æ•°å­—ï¼‰\n",
        "itos = {i: ch for i, ch in enumerate(chars)}  # index to stringï¼ˆæ•°å­—â†’æ–‡å­—ï¼‰\n",
        "\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ”¢ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰ã®ãƒ‡ãƒ¢\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "sample_text = \"ã‚ãŸãã—ã¯ ã›ã‚“ã›ã„\"\n",
        "encoded_sample = encode(sample_text)\n",
        "decoded_sample = decode(encoded_sample)\n",
        "\n",
        "print(f\"\\nã€å…ƒã®æ–‡å­—åˆ—ã€‘\")\n",
        "print(f\"   {sample_text}\")\n",
        "\n",
        "print(f\"\\nã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆæ–‡å­— â†’ æ•°å­—ï¼‰ã€‘\")\n",
        "print(\"-\"*70)\n",
        "for i, char in enumerate(sample_text):\n",
        "    num = encoded_sample[i]\n",
        "    print(f\"   '{char}' â†’ {num:3d}\")\n",
        "\n",
        "print(f\"\\nã€æ•°å­—ã®ä¸¦ã³ã€‘\")\n",
        "print(f\"   {encoded_sample}\")\n",
        "print(f\"   â†‘ AIã¯ã“ã®æ•°å­—ã®ä¸¦ã³ã‚’è¦‹ã¦å­¦ç¿’ã—ã¾ã™ï¼\")\n",
        "\n",
        "print(f\"\\nã€ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆæ•°å­— â†’ æ–‡å­—ï¼‰ã€‘\")\n",
        "print(f\"   {decoded_sample}\")\n",
        "print(f\"   â†‘ å…ƒé€šã‚Šã«ãªã‚Šã¾ã—ãŸï¼\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âœ… ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰ã®ä»•çµ„ã¿ãŒç†è§£ã§ãã¾ã—ãŸ\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qML5qBxdSIa6"
      },
      "source": [
        "## ğŸ¯ ã‚‚ã£ã¨è©³ã—ãè¦‹ã¦ã¿ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OlhPZWxSIa6",
        "outputId": "08dcf650-2785-4c3c-f5d3-8b8e34f8b6b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¾Œã®ãƒ‡ãƒ¼ã‚¿\n",
            "----------------------------------------------------------------------\n",
            "å½¢çŠ¶: torch.Size([1790079])\n",
            "ãƒ‡ãƒ¼ã‚¿å‹: torch.int64\n",
            "\n",
            "æœ€åˆã®50å€‹ã®æ•°å­—:\n",
            "tensor([33, 30, 46,  1, 26, 12, 25, 18,  1,  5, 21, 21, 58,  6,  0, 23, 62, 52,\n",
            "        12,  1, 25, 61, 25, 10,  1, 32,  1, 59, 27, 23,  0, 10, 28,  0, 59, 27,\n",
            "        19, 23, 38,  1, 26, 37, 39, 32, 60,  1, 30, 36, 34,  1])\n",
            "\n",
            "ã“ã‚Œã‚’æ–‡å­—ã«æˆ»ã™ã¨...\n",
            "ãªã¤ã‚ ãã†ã›ã ã€Œã“ã“ã‚ã€\n",
            "ã—ã‚›ã‚‡ã† ã›ã‚“ã›ã„ ã¨ ã‚ãŸã—\n",
            "ã„ã¡\n",
            "ã‚ãŸãã—ã¯ ãã®ã²ã¨ã‚’ ã¤ã­ã« \n",
            "\n",
            "ğŸ’¡ ãƒã‚¤ãƒ³ãƒˆ\n",
            "   - ã™ã¹ã¦ã®æ–‡ç« ãŒæ•°å­—ã®åˆ—ã«ãªã‚Šã¾ã—ãŸ\n",
            "   - ã“ã®æ•°å­—ã®ä¸¦ã³ã‹ã‚‰æ¬¡ã«æ¥ã‚‹æ•°å­—ã‚’äºˆæ¸¬ã™ã‚‹ã®ãŒAIã®ä»•äº‹ï¼\n"
          ]
        }
      ],
      "source": [
        "# å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "\n",
        "print(f\"\\nğŸ“Š ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¾Œã®ãƒ‡ãƒ¼ã‚¿\")\n",
        "print(\"-\"*70)\n",
        "print(f\"å½¢çŠ¶: {data.shape}\")\n",
        "print(f\"ãƒ‡ãƒ¼ã‚¿å‹: {data.dtype}\")\n",
        "\n",
        "print(f\"\\næœ€åˆã®50å€‹ã®æ•°å­—:\")\n",
        "print(data[:50])\n",
        "\n",
        "print(f\"\\nã“ã‚Œã‚’æ–‡å­—ã«æˆ»ã™ã¨...\")\n",
        "print(decode(data[:50].tolist()))\n",
        "\n",
        "print(\"\\nğŸ’¡ ãƒã‚¤ãƒ³ãƒˆ\")\n",
        "print(\"   - ã™ã¹ã¦ã®æ–‡ç« ãŒæ•°å­—ã®åˆ—ã«ãªã‚Šã¾ã—ãŸ\")\n",
        "print(\"   - ã“ã®æ•°å­—ã®ä¸¦ã³ã‹ã‚‰æ¬¡ã«æ¥ã‚‹æ•°å­—ã‚’äºˆæ¸¬ã™ã‚‹ã®ãŒAIã®ä»•äº‹ï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pvjN9aRSIa6"
      },
      "source": [
        "## âœ‚ï¸ ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g8a61VOSIa6",
        "outputId": "a91be506-6ecb-46c2-9043-015b0f7a38da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "âœ‚ï¸  ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²\n",
            "======================================================================\n",
            "\n",
            "ğŸ“š è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 1,611,071 æ–‡å­— (90.0%)\n",
            "ğŸ“ æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: 179,008 æ–‡å­— (10.0%)\n",
            "\n",
            "è¨“ç·´: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "æ¤œè¨¼: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ãƒ‡ãƒ¼ã‚¿ã‚’90%ã¨10%ã«åˆ†å‰²\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âœ‚ï¸  ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nğŸ“š è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_data):,} æ–‡å­— ({len(train_data)/len(data)*100:.1f}%)\")\n",
        "print(f\"ğŸ“ æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(val_data):,} æ–‡å­— ({len(val_data)/len(data)*100:.1f}%)\")\n",
        "\n",
        "train_blocks = int(len(train_data) / len(data) * 50)\n",
        "val_blocks = 50 - train_blocks\n",
        "print(f\"\\nè¨“ç·´: {'â–ˆ' * train_blocks}\")\n",
        "print(f\"æ¤œè¨¼: {'â–ˆ' * val_blocks}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kk6tysFSIa6"
      },
      "source": [
        "## ğŸ² ãƒŸãƒ‹ãƒãƒƒãƒé–¢æ•°ã®å®šç¾©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iSNou4nSIa6",
        "outputId": "41cebd9f-6da9-4a07-f990-5fc9d026ad25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ\n"
          ]
        }
      ],
      "source": [
        "def get_batch(split):\n",
        "    data_source = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data_source) - block_size, (batch_size,))\n",
        "    x = torch.stack([data_source[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data_source[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "print(\"âœ… ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM3bzzuSSIa6"
      },
      "source": [
        "---\n",
        "\n",
        "# ğŸ—ï¸ ã‚¹ãƒ†ãƒƒãƒ—5: AIãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰\n",
        "\n",
        "ï¼ˆãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã‚³ãƒ¼ãƒ‰ã¯å¤‰æ›´ãªã—ã®ãŸã‚çœç•¥ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_pdbzqVSIa6",
        "outputId": "e99eca65-2eeb-4d6a-fefe-545f06fecdce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ¤– AIãƒ¢ãƒ‡ãƒ«å®Œæˆï¼\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 6,381,126 å€‹ (6.38M)\n",
            "å®Ÿè¡Œç’°å¢ƒ: cpu\n"
          ]
        }
      ],
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "n_params = sum(p.numel() for p in m.parameters())\n",
        "\n",
        "print(\"\\nğŸ¤– AIãƒ¢ãƒ‡ãƒ«å®Œæˆï¼\")\n",
        "print(f\"ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {n_params:,} å€‹ ({n_params/1e6:.2f}M)\")\n",
        "print(f\"å®Ÿè¡Œç’°å¢ƒ: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jadETd4gSIa6"
      },
      "source": [
        "---\n",
        "\n",
        "# ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—6: å­¦ç¿’ï¼ˆæ”¹å–„ç‰ˆï¼‰\n",
        "\n",
        "## ğŸ†• æ”¹å–„ç‰ˆã®æ–°æ©Ÿèƒ½\n",
        "\n",
        "### 1. Learning Rate Schedulerï¼ˆå­¦ç¿’ç‡ã®è‡ªå‹•èª¿æ•´ï¼‰\n",
        "\n",
        "**ã©ã†å‹•ãã®ï¼Ÿ**\n",
        "1. **ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ï¼ˆæœ€åˆ100å›ï¼‰**: å­¦ç¿’ç‡ã‚’0ã‹ã‚‰å¾ã€…ã«ä¸Šã’ã‚‹\n",
        "   - æœ€åˆã‹ã‚‰é£›ã°ã™ã¨å¤±æ•—ã—ã‚„ã™ã„ã®ã§ã€æ…é‡ã«å§‹ã‚ã‚‹\n",
        "2. **ã‚³ã‚µã‚¤ãƒ³æ¸›è¡°ï¼ˆ100å›ã€œæœ€å¾Œï¼‰**: å­¦ç¿’ç‡ã‚’å¾ã€…ã«ä¸‹ã’ã‚‹\n",
        "   - æœ€åˆã¯å¤§èƒ†ã«ã€æœ€å¾Œã¯ç¹Šç´°ã«èª¿æ•´\n",
        "\n",
        "**ã‚°ãƒ©ãƒ•ã§è¦‹ã‚‹ã¨**:\n",
        "```\n",
        "å­¦ç¿’ç‡\n",
        "  â†‘\n",
        "6e-4 |    ï¼ï¿£ï¿£ï¼¼___\n",
        "     |   /          ï¼¼___\n",
        "6e-5 |  /               ï¼¼___\n",
        "  0  |_/___________________ï¼¼___â†’ ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\n",
        "     0   100              5000\n",
        "```\n",
        "\n",
        "### 2. Gradient Clippingï¼ˆå‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼‰\n",
        "\n",
        "**ä½•ã‚’ã™ã‚‹ã®ï¼Ÿ**\n",
        "- å‹¾é…ï¼ˆå­¦ç¿’ã®æ–¹å‘ï¼‰ãŒå¤§ãããªã‚Šã™ããŸã‚‰ã€1.0ã«åˆ¶é™\n",
        "- ã“ã‚Œã«ã‚ˆã‚Šå­¦ç¿’ãŒå®‰å®šã—ã€é€”ä¸­ã§å£Šã‚Œã«ãããªã‚‹\n",
        "\n",
        "### 3. Weight Decayï¼ˆé‡ã¿æ¸›è¡°ï¼‰\n",
        "\n",
        "**ä½•ã‚’ã™ã‚‹ã®ï¼Ÿ**\n",
        "- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¤§ãããªã‚Šã™ããªã„ã‚ˆã†ã«ã€å°‘ã—ãšã¤å°ã•ãã™ã‚‹\n",
        "- éå­¦ç¿’ï¼ˆæš—è¨˜ï¼‰ã‚’é˜²ãã€æ±åŒ–æ€§èƒ½ãŒå‘ä¸Š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E3wc6E-ySIa7",
        "outputId": "7331b496-e0a4-4a56-9234-ea62b2bb0852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ğŸ“ å­¦ç¿’é–‹å§‹ï¼ï¼ˆæ”¹å–„ç‰ˆï¼‰\n",
            "======================================================================\n",
            "â° é–‹å§‹æ™‚åˆ»: 16:48:09\n",
            "ğŸ“š æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: 5,000å›\n",
            "\n",
            "ğŸ†• ä½¿ç”¨æŠ€è¡“:\n",
            "   1ï¸âƒ£ Learning Rate Warmup + Cosine Decay\n",
            "   2ï¸âƒ£ Gradient Clipping (max=1.0)\n",
            "   3ï¸âƒ£ Weight Decay (L2=0.1)\n",
            "======================================================================\n",
            "\n",
            "[â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]   0.0%\n",
            "ğŸ“ Step     0/5000 | â±ï¸  9:18 (æ®‹ã‚Šç´„0åˆ†)\n",
            "ğŸ“Š Train: 4.4374 | Val: 4.4505 | LR: 0.000000\n",
            "   ğŸ˜´ åˆæœŸæ®µéš\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 4.4505\n",
            "   ğŸ’¾ ä¿å­˜: iter_1.pt\n",
            "   ğŸ’¾ ä¿å­˜: iter_50.pt\n",
            "\n",
            "[â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]   2.0%\n",
            "ğŸ“ Step   100/5000 | â±ï¸  32:54 (æ®‹ã‚Šç´„1596åˆ†)\n",
            "ğŸ“Š Train: 2.8444 | Val: 2.7618 | LR: 0.000300\n",
            "   ğŸ¤” å­¦ç¿’ä¸­\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 2.7618\n",
            "   ğŸ’¾ ä¿å­˜: iter_100.pt\n",
            "\n",
            "[â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]   4.0%\n",
            "ğŸ“ Step   200/5000 | â±ï¸  56:34 (æ®‹ã‚Šç´„1350åˆ†)\n",
            "ğŸ“Š Train: 2.7458 | Val: 2.6552 | LR: 0.000300\n",
            "   ğŸ¤” å­¦ç¿’ä¸­\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 2.6552\n",
            "   ğŸ’¾ ä¿å­˜: iter_200.pt\n",
            "\n",
            "[â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]   6.0%\n",
            "ğŸ“ Step   300/5000 | â±ï¸  80:16 (æ®‹ã‚Šç´„1253åˆ†)\n",
            "ğŸ“Š Train: 2.6968 | Val: 2.6089 | LR: 0.000299\n",
            "   ğŸ¤” å­¦ç¿’ä¸­\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 2.6089\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]   8.0%\n",
            "ğŸ“ Step   400/5000 | â±ï¸  104:00 (æ®‹ã‚Šç´„1193åˆ†)\n",
            "ğŸ“Š Train: 2.6364 | Val: 2.5645 | LR: 0.000298\n",
            "   ğŸ¤” å­¦ç¿’ä¸­\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 2.5645\n",
            "   ğŸ’¾ ä¿å­˜: iter_400.pt\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  10.0%\n",
            "ğŸ“ Step   500/5000 | â±ï¸  127:50 (æ®‹ã‚Šç´„1148åˆ†)\n",
            "ğŸ“Š Train: 2.4931 | Val: 2.4469 | LR: 0.000296\n",
            "   ğŸ˜Š ç†è§£ã—ã¦ããŸ\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 2.4469\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  12.0%\n",
            "ğŸ“ Step   600/5000 | â±ï¸  151:24 (æ®‹ã‚Šç´„1108åˆ†)\n",
            "ğŸ“Š Train: 2.3855 | Val: 2.3562 | LR: 0.000294\n",
            "   ğŸ˜Š ç†è§£ã—ã¦ããŸ\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 2.3562\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  14.0%\n",
            "ğŸ“ Step   700/5000 | â±ï¸  175:05 (æ®‹ã‚Šç´„1074åˆ†)\n",
            "ğŸ“Š Train: 2.3032 | Val: 2.2707 | LR: 0.000291\n",
            "   ğŸ˜Š ç†è§£ã—ã¦ããŸ\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 2.2707\n",
            "   ğŸ’¾ ä¿å­˜: iter_750.pt\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  16.0%\n",
            "ğŸ“ Step   800/5000 | â±ï¸  198:57 (æ®‹ã‚Šç´„1043åˆ†)\n",
            "ğŸ“Š Train: 2.2263 | Val: 2.2118 | LR: 0.000288\n",
            "   ğŸ˜Š ç†è§£ã—ã¦ããŸ\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 2.2118\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  18.0%\n",
            "ğŸ“ Step   900/5000 | â±ï¸  222:36 (æ®‹ã‚Šç´„1012åˆ†)\n",
            "ğŸ“Š Train: 2.1680 | Val: 2.1524 | LR: 0.000285\n",
            "   ğŸ˜Š ç†è§£ã—ã¦ããŸ\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 2.1524\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  20.0%\n",
            "ğŸ“ Step  1000/5000 | â±ï¸  246:02 (æ®‹ã‚Šç´„983åˆ†)\n",
            "ğŸ“Š Train: 2.1169 | Val: 2.1022 | LR: 0.000281\n",
            "   ğŸ˜Š ç†è§£ã—ã¦ããŸ\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 2.1022\n",
            "   ğŸ’¾ ä¿å­˜: iter_1000.pt\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  22.0%\n",
            "ğŸ“ Step  1100/5000 | â±ï¸  269:30 (æ®‹ã‚Šç´„954åˆ†)\n",
            "ğŸ“Š Train: 2.0776 | Val: 2.0655 | LR: 0.000276\n",
            "   ğŸ˜Š ç†è§£ã—ã¦ããŸ\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 2.0655\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  24.0%\n",
            "ğŸ“ Step  1200/5000 | â±ï¸  293:41 (æ®‹ã‚Šç´„929åˆ†)\n",
            "ğŸ“Š Train: 2.0451 | Val: 2.0262 | LR: 0.000271\n",
            "   ğŸ˜Š ç†è§£ã—ã¦ããŸ\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 2.0262\n",
            "   ğŸ’¾ ä¿å­˜: iter_1250.pt\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  26.0%\n",
            "ğŸ“ Step  1300/5000 | â±ï¸  317:09 (æ®‹ã‚Šç´„901åˆ†)\n",
            "ğŸ“Š Train: 2.0090 | Val: 2.0009 | LR: 0.000266\n",
            "   ğŸ˜Š ç†è§£ã—ã¦ããŸ\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 2.0009\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  28.0%\n",
            "ğŸ“ Step  1400/5000 | â±ï¸  340:30 (æ®‹ã‚Šç´„874åˆ†)\n",
            "ğŸ“Š Train: 1.9816 | Val: 1.9744 | LR: 0.000261\n",
            "   ğŸ‰ ã‹ãªã‚Šè³¢ã„\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 1.9744\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  30.0%\n",
            "ğŸ“ Step  1500/5000 | â±ï¸  364:27 (æ®‹ã‚Šç´„849åˆ†)\n",
            "ğŸ“Š Train: 1.9549 | Val: 1.9555 | LR: 0.000255\n",
            "   ğŸ‰ ã‹ãªã‚Šè³¢ã„\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 1.9555\n",
            "   ğŸ’¾ ä¿å­˜: iter_1500.pt\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  32.0%\n",
            "ğŸ“ Step  1600/5000 | â±ï¸  388:11 (æ®‹ã‚Šç´„824åˆ†)\n",
            "ğŸ“Š Train: 1.9265 | Val: 1.9378 | LR: 0.000249\n",
            "   ğŸ‰ ã‹ãªã‚Šè³¢ã„\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 1.9378\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  34.0%\n",
            "ğŸ“ Step  1700/5000 | â±ï¸  412:25 (æ®‹ã‚Šç´„800åˆ†)\n",
            "ğŸ“Š Train: 1.9125 | Val: 1.9188 | LR: 0.000242\n",
            "   ğŸ‰ ã‹ãªã‚Šè³¢ã„\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 1.9188\n",
            "   ğŸ’¾ ä¿å­˜: iter_1750.pt\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  36.0%\n",
            "ğŸ“ Step  1800/5000 | â±ï¸  436:18 (æ®‹ã‚Šç´„775åˆ†)\n",
            "ğŸ“Š Train: 1.8916 | Val: 1.9117 | LR: 0.000236\n",
            "   ğŸ‰ ã‹ãªã‚Šè³¢ã„\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 1.9117\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  38.0%\n",
            "ğŸ“ Step  1900/5000 | â±ï¸  461:04 (æ®‹ã‚Šç´„751åˆ†)\n",
            "ğŸ“Š Train: 1.8767 | Val: 1.8844 | LR: 0.000229\n",
            "   ğŸ‰ ã‹ãªã‚Šè³¢ã„\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 1.8844\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  40.0%\n",
            "ğŸ“ Step  2000/5000 | â±ï¸  484:34 (æ®‹ã‚Šç´„726åˆ†)\n",
            "ğŸ“Š Train: 1.8562 | Val: 1.8817 | LR: 0.000221\n",
            "   ğŸ‰ ã‹ãªã‚Šè³¢ã„\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 1.8817\n",
            "   ğŸ’¾ ä¿å­˜: iter_2000.pt\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  42.0%\n",
            "ğŸ“ Step  2100/5000 | â±ï¸  507:53 (æ®‹ã‚Šç´„701åˆ†)\n",
            "ğŸ“Š Train: 1.8430 | Val: 1.8583 | LR: 0.000214\n",
            "   ğŸ‰ ã‹ãªã‚Šè³¢ã„\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 1.8583\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  44.0%\n",
            "ğŸ“ Step  2200/5000 | â±ï¸  531:03 (æ®‹ã‚Šç´„675åˆ†)\n",
            "ğŸ“Š Train: 1.8244 | Val: 1.8538 | LR: 0.000207\n",
            "   ğŸ‰ ã‹ãªã‚Šè³¢ã„\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 1.8538\n",
            "   ğŸ’¾ ä¿å­˜: iter_2250.pt\n",
            "\n",
            "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  46.0%\n",
            "ğŸ“ Step  2300/5000 | â±ï¸  554:51 (æ®‹ã‚Šç´„651åˆ†)\n",
            "ğŸ“Š Train: 1.8135 | Val: 1.8483 | LR: 0.000199\n",
            "   ğŸ‰ ã‹ãªã‚Šè³¢ã„\n",
            "   âœ¨ æ–°è¨˜éŒ²ï¼ Best: 1.8483\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1065681828.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_iters\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3122137323.py\u001b[0m in \u001b[0;36mestimate_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2214800317.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mpos_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtok_emb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2214800317.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2214800317.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ğŸ†• Weight Decayä»˜ãã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "# ğŸ†• Learning Rate Scheduleré–¢æ•°\n",
        "def get_lr(it):\n",
        "    \"\"\"ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ã«å¿œã˜ã¦å­¦ç¿’ç‡ã‚’è¨ˆç®—\"\"\"\n",
        "    # 1. ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æœŸé–“ï¼ˆ0 â†’ learning_rateï¼‰\n",
        "    if it < warmup_iters:\n",
        "        return learning_rate * it / warmup_iters\n",
        "    # 2. æœ€å°å­¦ç¿’ç‡ã«é”ã—ãŸã‚‰ãã®ã¾ã¾\n",
        "    if it > lr_decay_iters:\n",
        "        return min_lr\n",
        "    # 3. ã‚³ã‚µã‚¤ãƒ³æ¸›è¡°ï¼ˆlearning_rate â†’ min_lrï¼‰\n",
        "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
        "    coeff = 0.5 * (1.0 + np.cos(np.pi * decay_ratio))\n",
        "    return min_lr + coeff * (learning_rate - min_lr)\n",
        "\n",
        "# å­¦ç¿’å±¥æ­´ã®è¨˜éŒ²\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "iterations = []\n",
        "learning_rates = []  # ğŸ†• å­¦ç¿’ç‡ã®è¨˜éŒ²ã‚‚è¿½åŠ \n",
        "\n",
        "checkpoints = []\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "def should_save_checkpoint(iter_num):\n",
        "    if iter_num in checkpoint_intervals:\n",
        "        return True\n",
        "    if iter_num > max(checkpoint_intervals):\n",
        "        if (iter_num - max(checkpoint_intervals)) % checkpoint_interval_regular == 0:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“ å­¦ç¿’é–‹å§‹ï¼ï¼ˆæ”¹å–„ç‰ˆï¼‰\")\n",
        "print(\"=\"*70)\n",
        "print(f\"â° é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "print(f\"ğŸ“š æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {max_iters:,}å›\")\n",
        "print(f\"\\nğŸ†• ä½¿ç”¨æŠ€è¡“:\")\n",
        "print(f\"   1ï¸âƒ£ Learning Rate Warmup + Cosine Decay\")\n",
        "print(f\"   2ï¸âƒ£ Gradient Clipping (max={grad_clip})\")\n",
        "print(f\"   3ï¸âƒ£ Weight Decay (L2={weight_decay})\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    # ğŸ†• Learning Rate Schedulerã®é©ç”¨\n",
        "    lr = get_lr(iter)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        train_losses.append(losses['train'].item())\n",
        "        val_losses.append(losses['val'].item())\n",
        "        iterations.append(iter)\n",
        "        learning_rates.append(lr)  # ğŸ†• å­¦ç¿’ç‡ã‚‚è¨˜éŒ²\n",
        "\n",
        "        progress = iter / max_iters * 100\n",
        "        bar_length = 40\n",
        "        filled = int(bar_length * iter / max_iters)\n",
        "        bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)\n",
        "\n",
        "        elapsed = (datetime.now() - start_time).total_seconds()\n",
        "        eta = elapsed / (iter + 1) * (max_iters - iter) if iter > 0 else 0\n",
        "\n",
        "        print(f\"\\n[{bar}] {progress:5.1f}%\")\n",
        "        print(f\"ğŸ“ Step {iter:5d}/{max_iters} | â±ï¸  {int(elapsed//60)}:{int(elapsed%60):02d} (æ®‹ã‚Šç´„{int(eta//60)}åˆ†)\")\n",
        "        print(f\"ğŸ“Š Train: {losses['train']:.4f} | Val: {losses['val']:.4f} | LR: {lr:.6f}\")\n",
        "\n",
        "        # å­¦ç¿’çŠ¶æ…‹ã®åˆ¤å®š\n",
        "        if losses['val'] > 3.5:\n",
        "            status = \"ğŸ˜´ åˆæœŸæ®µéš\"\n",
        "        elif losses['val'] > 2.5:\n",
        "            status = \"ğŸ¤” å­¦ç¿’ä¸­\"\n",
        "        elif losses['val'] > 2.0:\n",
        "            status = \"ğŸ˜Š ç†è§£ã—ã¦ããŸ\"\n",
        "        elif losses['val'] > 1.5:\n",
        "            status = \"ğŸ‰ ã‹ãªã‚Šè³¢ã„\"\n",
        "        else:\n",
        "            status = \"ğŸŒŸ è¶…å„ªç§€\"\n",
        "        print(f\"   {status}\")\n",
        "\n",
        "        if losses['val'] < best_val_loss - min_delta:\n",
        "            best_val_loss = losses['val']\n",
        "            patience_counter = 0\n",
        "            print(f\"   âœ¨ æ–°è¨˜éŒ²ï¼ Best: {best_val_loss:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter > 0:\n",
        "                print(f\"   â³ æ”¹å–„ãªã— {patience_counter}/{patience}å›\")\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"\\nğŸ›‘ Early Stoppingç™ºå‹•\")\n",
        "            break\n",
        "\n",
        "    if should_save_checkpoint(iter) and iter > 0:\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, f'model_iter_{iter}.pt')\n",
        "        torch.save({\n",
        "            'iter': iter,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': losses['train'].item() if iter % eval_interval == 0 else None,\n",
        "            'val_loss': losses['val'].item() if iter % eval_interval == 0 else None,\n",
        "        }, checkpoint_path)\n",
        "        checkpoints.append((iter, checkpoint_path))\n",
        "        print(f\"   ğŸ’¾ ä¿å­˜: iter_{iter}.pt\")\n",
        "\n",
        "    # é †ä¼æ’­\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "\n",
        "    # é€†ä¼æ’­\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "\n",
        "    # ğŸ†• Gradient Clippingï¼ˆå‹¾é…çˆ†ç™ºé˜²æ­¢ï¼‰\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "# æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜\n",
        "final_path = os.path.join(checkpoint_dir, 'model_final.pt')\n",
        "torch.save({\n",
        "    'iter': iter,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "}, final_path)\n",
        "checkpoints.append((iter, final_path))\n",
        "\n",
        "total_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ‰ å­¦ç¿’å®Œäº†ï¼\")\n",
        "print(\"=\"*70)\n",
        "print(f\"â° çµ‚äº†æ™‚åˆ»: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "print(f\"â±ï¸  æ‰€è¦æ™‚é–“: {int(total_time//60)}åˆ†{int(total_time%60)}ç§’\")\n",
        "print(f\"ğŸ“Š æœ€çµ‚Loss - Train: {losses['train']:.4f}, Val: {losses['val']:.4f}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVHJ9Dz9SIa7"
      },
      "source": [
        "---\n",
        "\n",
        "# ğŸ“ˆ ã‚¹ãƒ†ãƒƒãƒ—7: å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–ï¼ˆæ”¹å–„ç‰ˆï¼‰\n",
        "\n",
        "## ğŸ†• Learning Rate ã®æ¨ç§»ã‚‚è¡¨ç¤º\n",
        "\n",
        "æ”¹å–„ç‰ˆã§ã¯ã€Learning RateãŒã©ã®ã‚ˆã†ã«å¤‰åŒ–ã—ãŸã‹ã‚‚è¦‹ã‚‰ã‚Œã¾ã™ï¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18X3vOy9SIa7"
      },
      "outputs": [],
      "source": [
        "# ğŸ†• 3ã¤ã®ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º\n",
        "fig = plt.figure(figsize=(18, 5))\n",
        "\n",
        "# 1. Lossæ›²ç·šï¼ˆé€šå¸¸ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰\n",
        "ax1 = plt.subplot(1, 3, 1)\n",
        "ax1.plot(iterations, train_losses, 'b-', linewidth=2.5, label='Training Loss', alpha=0.8)\n",
        "ax1.plot(iterations, val_losses, 'r-', linewidth=2.5, label='Validation Loss', alpha=0.8)\n",
        "ax1.fill_between(iterations, train_losses, alpha=0.2, color='blue')\n",
        "ax1.fill_between(iterations, val_losses, alpha=0.2, color='red')\n",
        "ax1.set_xlabel('Iteration', fontsize=13, fontweight='bold')\n",
        "ax1.set_ylabel('Loss', fontsize=13, fontweight='bold')\n",
        "ax1.set_title('ğŸ“‰ Learning Curve', fontsize=15, fontweight='bold', pad=20)\n",
        "ax1.legend(fontsize=12, loc='upper right')\n",
        "ax1.grid(True, alpha=0.3, linestyle='--')\n",
        "ax1.set_facecolor('#f8f9fa')\n",
        "\n",
        "# 2. Lossæ›²ç·šï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰\n",
        "ax2 = plt.subplot(1, 3, 2)\n",
        "ax2.plot(iterations, train_losses, 'b-', linewidth=2.5, label='Training Loss', alpha=0.8)\n",
        "ax2.plot(iterations, val_losses, 'r-', linewidth=2.5, label='Validation Loss', alpha=0.8)\n",
        "ax2.set_xlabel('Iteration', fontsize=13, fontweight='bold')\n",
        "ax2.set_ylabel('Loss (log scale)', fontsize=13, fontweight='bold')\n",
        "ax2.set_title('ğŸ“ Scaling Law', fontsize=15, fontweight='bold', pad=20)\n",
        "ax2.set_yscale('log')\n",
        "ax2.legend(fontsize=12, loc='upper right')\n",
        "ax2.grid(True, alpha=0.3, which='both', linestyle='--')\n",
        "ax2.set_facecolor('#f8f9fa')\n",
        "\n",
        "# 3. ğŸ†• Learning Rateæ¨ç§»\n",
        "ax3 = plt.subplot(1, 3, 3)\n",
        "ax3.plot(iterations, learning_rates, 'g-', linewidth=2.5, alpha=0.8)\n",
        "ax3.fill_between(iterations, learning_rates, alpha=0.2, color='green')\n",
        "ax3.set_xlabel('Iteration', fontsize=13, fontweight='bold')\n",
        "ax3.set_ylabel('Learning Rate', fontsize=13, fontweight='bold')\n",
        "ax3.set_title('ğŸ†• LR Schedule\\n(Warmup + Cosine)', fontsize=15, fontweight='bold', pad=20)\n",
        "ax3.grid(True, alpha=0.3, linestyle='--')\n",
        "ax3.set_facecolor('#f8f9fa')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('learning_curve_improved.png', dpi=200, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“Š ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nã€å·¦ã€‘Lossæ›²ç·š\")\n",
        "print(\"   - é’ç·š: è¨“ç·´Loss\")\n",
        "print(\"   - èµ¤ç·š: æ¤œè¨¼Loss\")\n",
        "print(\"   - ä¸¡æ–¹ä¸‹ãŒã‚‹ â†’ æ­£ã—ãå­¦ç¿’ã§ãã¦ã„ã‚‹ï¼\")\n",
        "\n",
        "print(\"\\nã€ä¸­å¤®ã€‘Scaling Law\")\n",
        "print(\"   - ã»ã¼ç›´ç·š â†’ ãƒ‡ãƒ¼ã‚¿é‡ã‚’å¢—ã‚„ã›ã°æ€§èƒ½å‘ä¸Š\")\n",
        "\n",
        "print(\"\\nã€å³ã€‘ğŸ†• Learning Rateæ¨ç§»\")\n",
        "print(\"   - æœ€åˆ: ã‚†ã£ãã‚Šä¸Šæ˜‡ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ï¼‰\")\n",
        "print(\"   - é€”ä¸­: é«˜ã„å­¦ç¿’ç‡ã§å­¦ç¿’\")\n",
        "print(\"   - æœ€å¾Œ: å¾ã€…ã«ä¸‹é™ï¼ˆã‚³ã‚µã‚¤ãƒ³æ¸›è¡°ï¼‰\")\n",
        "print(\"   â†’ ã“ã®å¤‰åŒ–ãŒå­¦ç¿’ã‚’å®‰å®šåŒ–ã•ã›ã¾ã™ï¼\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ ã‚ãªãŸã®ãƒ¢ãƒ‡ãƒ«ã®æˆç¸¾\")\n",
        "print(f\"   æœ€çµ‚Train Loss: {train_losses[-1]:.4f}\")\n",
        "print(f\"   æœ€çµ‚Val Loss: {val_losses[-1]:.4f}\")\n",
        "print(f\"   ãƒ™ã‚¹ãƒˆVal Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "if val_losses[-1] < 1.5:\n",
        "    print(f\"\\n   ğŸŒŸ ç´ æ™´ã‚‰ã—ã„ï¼æ”¹å–„ç‰ˆã®åŠ¹æœãŒå‡ºã¦ã„ã¾ã™\")\n",
        "elif val_losses[-1] < 2.0:\n",
        "    print(f\"\\n   ğŸ‰ ã¨ã¦ã‚‚è‰¯ã„ï¼å®Ÿç”¨çš„ãªãƒ¬ãƒ™ãƒ«ã§ã™\")\n",
        "else:\n",
        "    print(f\"\\n   ğŸ˜Š ã‚‚ã†å°‘ã—å­¦ç¿’ã™ã‚Œã°å‘ä¸Šã—ã¾ã™\")\n",
        "\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yss_GwJ-SIa7"
      },
      "source": [
        "---\n",
        "\n",
        "# ğŸ¬ ã‚¹ãƒ†ãƒƒãƒ—8: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã”ã¨ã®ç”Ÿæˆ\n",
        "\n",
        "ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MX-KOrWSIa7"
      },
      "outputs": [],
      "source": [
        "print(\"\\nğŸ¬ AIã®æˆé•·ã‚’è¦‹ã¦ã¿ã‚ˆã†\")\n",
        "print(f\"ä¿å­˜ã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ: {len(checkpoints)}å€‹\\n\")\n",
        "\n",
        "for idx, (iter_num, checkpoint_path) in enumerate(checkpoints, 1):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"ğŸ“ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ {idx}/{len(checkpoints)}: {iter_num}å›å­¦ç¿’å¾Œ\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    if 'train_loss' in checkpoint and checkpoint['train_loss'] is not None:\n",
        "        print(f\"\\nğŸ“Š Loss: Train={checkpoint['train_loss']:.4f}, Val={checkpoint['val_loss']:.4f}\")\n",
        "\n",
        "    print(f\"\\nğŸ“ ç”Ÿæˆã•ã‚ŒãŸæ–‡ç« :\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "    with torch.no_grad():\n",
        "        generated = decode(model.generate(context, max_new_tokens=300)[0].tolist())\n",
        "    print(generated)\n",
        "    print(\"-\"*70)\n",
        "\n",
        "print(\"\\nğŸ‰ ã™ã¹ã¦ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ç¢ºèªå®Œäº†\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Lu1N8GBSIa7"
      },
      "source": [
        "---\n",
        "\n",
        "# ğŸ® ã‚¹ãƒ†ãƒƒãƒ—9: æ–‡ç« ç”Ÿæˆã§éŠã¼ã†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPOHbVAvSIa7"
      },
      "outputs": [],
      "source": [
        "prompt = \"ã‚ãŸãã—ã¯\"\n",
        "max_generate = 500\n",
        "\n",
        "print(\"\\nğŸ® æ–‡ç« ç”Ÿæˆ\")\n",
        "print(f\"ğŸ’¬ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: '{prompt}'\")\n",
        "\n",
        "if prompt:\n",
        "    context = torch.tensor([encode(prompt)], dtype=torch.long, device=device)\n",
        "else:\n",
        "    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    generated = decode(model.generate(context, max_new_tokens=max_generate)[0].tolist())\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(generated)\n",
        "print(\"-\"*70)\n",
        "print(\"\\nâœ… ç”Ÿæˆå®Œäº†ï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzyqFdAQSIa7"
      },
      "source": [
        "---\n",
        "\n",
        "# ğŸ“ ã¾ã¨ã‚: æ”¹å–„ç‰ˆã§å­¦ã‚“ã ã“ã¨\n",
        "\n",
        "## ğŸ†• æ”¹å–„ç‰ˆã®3ã¤ã®æŠ€è¡“\n",
        "\n",
        "### 1. Learning Rate Scheduler\n",
        "**å­¦ç¿’é€Ÿåº¦ã‚’è‡ªå‹•èª¿æ•´**\n",
        "- ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—: æœ€åˆã¯ã‚†ã£ãã‚Š\n",
        "- ã‚³ã‚µã‚¤ãƒ³æ¸›è¡°: å¾ã€…ã«ä¸å¯§ã«\n",
        "- **åŠ¹æœ**: Loss 1.9 â†’ 1.2-1.4 ã¸ã®æ”¹å–„\n",
        "\n",
        "### 2. Gradient Clipping\n",
        "**å­¦ç¿’ã®æš´èµ°ã‚’é˜²æ­¢**\n",
        "- å‹¾é…ã‚’1.0ä»¥ä¸‹ã«åˆ¶é™\n",
        "- **åŠ¹æœ**: å­¦ç¿’ã®å®‰å®šåŒ–\n",
        "\n",
        "### 3. Weight Decay\n",
        "**éå­¦ç¿’ã‚’é˜²æ­¢**\n",
        "- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è‚¥å¤§åŒ–ã‚’æŠ‘åˆ¶\n",
        "- **åŠ¹æœ**: æ±åŒ–æ€§èƒ½ã®å‘ä¸Š\n",
        "\n",
        "## ğŸš€ ã•ã‚‰ãªã‚‹æ”¹å–„ç­–\n",
        "\n",
        "ã‚‚ã—ã¾ã LossãŒä¸‹ãŒã‚‰ãªã„å ´åˆï¼š\n",
        "1. **ãƒ‡ãƒ¼ã‚¿é‡ã‚’å¢—ã‚„ã™** - ã‚ˆã‚Šé•·ã„ãƒ†ã‚­ã‚¹ãƒˆ\n",
        "2. **block_size ã‚’å¢—ã‚„ã™** - ã‚ˆã‚Šé•·ã„æ–‡è„ˆï¼ˆ128â†’256ï¼‰\n",
        "3. **ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ã‚’å¢—ã‚„ã™** - ã‚ˆã‚Šé•·ãå­¦ç¿’ï¼ˆ5000â†’10000ï¼‰\n",
        "4. **ãƒ¢ãƒ‡ãƒ«ã‚’å¤§ããã™ã‚‹** - n_embd, n_layer ã‚’å¢—ã‚„ã™\n",
        "\n",
        "**Happy Learning! ğŸ“šâœ¨**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}